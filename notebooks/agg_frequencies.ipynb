{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "import torch as th"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.attn = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.v = nn.Parameter(torch.rand(hidden_size))\n",
    "\n",
    "    def forward(self, encoder_outputs, hidden):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        seq_len = encoder_outputs.size(1)\n",
    "        energy = F.relu(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
    "        energy = energy.transpose(1, 2)\n",
    "        v = self.v.repeat(batch_size, 1).unsqueeze(1)\n",
    "        print(v.size(), energy.size())\n",
    "        attention_scores = torch.bmm(v, energy).squeeze(1)\n",
    "        print(attention_scores.size())\n",
    "        return F.softmax(attention_scores, dim=1)\n",
    "\n",
    "class SpectrogramAttentionModel(nn.Module):\n",
    "    def __init__(self, cnn_output_dim, hidden_size, output_dim):\n",
    "        super(SpectrogramAttentionModel, self).__init__()\n",
    "        self.attention = Attention(cnn_output_dim)\n",
    "        self.fc = nn.Linear(cnn_output_dim, hidden_size)\n",
    "        self.output_layer = nn.Linear(hidden_size, output_dim)\n",
    "\n",
    "    def forward(self, cnn_output):\n",
    "        batch_size, time_steps, frequency_channels, features = cnn_output.size()\n",
    "        cnn_output = cnn_output.view(batch_size * time_steps, frequency_channels, features)\n",
    "        attention_weights = self.attention(cnn_output, cnn_output)\n",
    "        print(attention_weights.size())\n",
    "        attended_output = torch.bmm(attention_weights.unsqueeze(1), cnn_output).squeeze(1)\n",
    "        fc_output = F.relu(self.fc(attended_output))\n",
    "        output = self.output_layer(fc_output)\n",
    "        return output.view(batch_size, time_steps, -1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe61dc5972391810",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "x = torch.randn(2, 16, 128, 5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95d5b9a6f2824611",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "s = SpectrogramAttentionModel(5, 3, 5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2306b94b2426be1c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "o = s(x)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74411242bdedf9d7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "o.size()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d58eb3e0c91d9128",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class AggregateFrequencies(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dim: int, output_dim: int) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.__to_input = nn.Linear(input_dim, hidden_dim)\n",
    "        self.__to_key = nn.Linear(input_dim, hidden_dim)\n",
    "        self.__to_value = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x: th.Tensor) -> th.Tensor:\n",
    "        b, c, w, h = x.size()\n",
    "\n",
    "        x = x.permute(0, 3, 2, 1).contiguous().view(b * h, w, c)\n",
    "\n",
    "        q = self.__to_input(x)\n",
    "        k = self.__to_key(x).transpose(1, 2)\n",
    "        v = self.__to_value(x)\n",
    "        \n",
    "        weight = F.softmax(th.bmm(q, k), dim=1).transpose(1, 2)\n",
    "\n",
    "        out = (\n",
    "            th.bmm(weight, v).sum(dim=1).view(b, h, -1)\n",
    "        )\n",
    "\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14da2a48f6518b49",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "agg = AggregateFrequencies(3, 6, 5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8816965c7a1db498",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "x = torch.rand(2, 3, 16, 32)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c18b8b05780c23a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "o = agg(x)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a3a8a4c303fd662",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "o.size()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2db5241c0ee6e67d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b52116bd3c41cdd9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
