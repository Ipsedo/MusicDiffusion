{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Démo DDPM\n",
    "\n",
    "## Definition\n",
    "\n",
    "Les diffusions modèles (ici [DDPM](https://arxiv.org/abs/2006.11239) sont une branche d'algorithmes utilisés pour la génération de données.\n",
    "\n",
    "![](https://learnopencv.com/wp-content/uploads/2023/01/diffusion-models-forwardbackward_process_ddpm.png)\n",
    "\n",
    "Le principe est simple, il y a un premier processus de diffusion consistant à ajouter progressivement du bruit à la donnée. Ce processus de diffusion consiste en une chaine de markov où il est possible d'obtenir la donnée à t + 1 (donc un peu plus bruitée) à partir de la donnée à un temps t :\n",
    "![](https://learnopencv.com/wp-content/uploads/2023/02/denoising-diffusion-probabilistic-models_forward_diffusion_equations_1.png)\n",
    "\n",
    "où les betas représentent la variance à un temps t, et sont croissants linéairement sur 1000 étapes de 1e-4 (beta 0) à 2e-2 (beta 1000).\n",
    "\n",
    "Le tout donne en code (avec PyTorch) :\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch as th\n",
    "from torch import nn\n",
    "from torchvision.transforms.functional import to_tensor\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from typing import Literal"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!wget https://media.cnn.com/api/v1/images/stellar/prod/190430171751-mona-lisa.jpg\n",
    "\n",
    "x_0 = to_tensor(Image.open(\"./190430171751-mona-lisa.jpg\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "T = 100\n",
    "beta_1 = 1e-3\n",
    "beta_t = 2e-1\n",
    "\n",
    "betas = th.linspace(beta_1, beta_t, steps=T)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def q_step(x_t_prev: th.Tensor, t: int) -> th.Tensor:\n",
    "    z = th.randn_like(x_t_prev)\n",
    "    return (1 - betas[t]) * x_t_prev + z * betas[t]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_1 = q_step(x_0, 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_0.size(), x_1.size()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.imshow(x_0.permute(1, 2, 0))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.imshow(x_1.permute(1, 2, 0))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_t_list = [x_0]\n",
    "\n",
    "for t in tqdm(range(1, T)):\n",
    "    x_t_list.append(q_step(x_t_list[-1], t))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.imshow(x_t_list[25].permute(1, 2, 0))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.imshow(x_t_list[40].permute(1, 2, 0))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.imshow(x_t_list[-1].permute(1, 2, 0))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3 secondes pour \"diffuser\" une image, c'est trop ! Les auteurs proposent une simplification permettant d'obtenir n'import quel x (de t = 1 à t = T) à partir de la donnée originelle, le x à t = 0 :\n",
    "\n",
    "![](https://miro.medium.com/v2/resize:fit:660/1*SRUnVsytTzuCWLvu7tA4gA.png)\n",
    "\n",
    "Ce qui donne en code :"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "alphas = 1 - betas\n",
    "alphas_cum_prod = th.cumprod(alphas, dim=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def q_sample(x_0: th.Tensor, t: int) -> th.Tensor:\n",
    "    z = th.randn_like(x_0)\n",
    "    return th.sqrt(alphas_cum_prod[t]) * x_0 + (1 - alphas_cum_prod[t]) * z"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_10 = q_sample(x_0, 10)\n",
    "plt.matshow(x_10.permute(1, 2, 0))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_30 = q_sample(x_0, 30)\n",
    "plt.matshow(x_30.permute(1, 2, 0))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_70 = q_sample(x_0, 70)\n",
    "plt.matshow(x_70.permute(1, 2, 0))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reverse process - denoising process\n",
    "\n",
    "C'est ok pour le processus de diffusion, qu'en est-il pour le coeur du sujet : le processus inverse aka le dé-bruitage ?\n",
    "\n",
    "Il s'agit aussi d'une chaine de markov : à une étape t, il faut prédire la moyenne et la matrice de covariance qui ont servi à ajouter le bruit à l'étape précédente (pour passer de t - 1 à t) :\n",
    "\n",
    "![](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRCZCpFnGkY_TCOPvvy-W3rOBuKR-ZPTbx6Pg&usqp=CAU)\n",
    "\n",
    "Le modèle reçoit deux paramètres :\n",
    "- la donnée bruitée\n",
    "- l'indice dans la chaine de markov\n",
    "\n",
    "Les auteurs simplifient le tout (en rapport au processus de diffusion / bruitage amélioré) : *\n",
    "- on oublie la matrice de covariance du fait que la variance sera constante (matrice identité avec comme facteur beta)\n",
    "- on ne prédit plus la moyenne de la distribution normale mais directement le bruit\n",
    "\n",
    "Le tout donne en algorithme :\n",
    "\n",
    "![](https://huggingface.co/blog/assets/78_annotated-diffusion/training.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## U-Net architecture\n",
    "\n",
    "Il nous faut une architecture de réseau de neurones qui puisse à partir d'une image, produire une image de mêmes dimensions mais dans un espace de canaux / pixels / couleurs différent. Ici l'espace à prédire pour les pixels sera le bruit qui a été ajouté.\n",
    "\n",
    "L'architecture U-Net sera parfaite : elle a fait ses preuves dans le biomédical pour de la segmentation d'images (plus généralement passer dans un autre espace de couleurs / canaux / pixels). Elle consiste en deux parties :\n",
    "- un encodeur\n",
    "- un décodeur\n",
    "Ces deux parties sont liées au niveau de la sortie de l'encodeur et de l'entrée du décodeur mais aussi par des connexions directes entre les couches de l'encodeur vers le décodeur :\n",
    "\n",
    "![](https://miro.medium.com/v2/resize:fit:1400/1*f7YOaE4TWubwaFF7Z1fzNw.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### L'élément de base : la convolution\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/0/04/Convolution_arithmetic_-_Padding_strides.gif?20190413174630)\n",
    "\n",
    "![](https://miro.medium.com/v2/resize:fit:640/1*ZCjPUFrB6eHPRi4eyP6aaA.gif)\n",
    "\n",
    "Nous allons créer notre block (ou couche) de base comprenant :\n",
    "- une convolution 3 x 3\n",
    "- une activation : Mish\n",
    "- une couche de normalisation : GroupNorm\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Sequential):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        group_norm: int,\n",
    "    ) -> None:\n",
    "        super().__init__(\n",
    "            nn.Conv2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size=(3, 3),\n",
    "                padding=(1, 1),\n",
    "                stride=(1, 1),\n",
    "            ),\n",
    "            nn.Mish(),\n",
    "            nn.GroupNorm(group_norm, out_channels),\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "block_1 = ConvBlock(3, 8, 4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_30.size()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_30 = x_30.unsqueeze(0)\n",
    "out = block_1(x_30)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "out.size()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Up sample / down sample\n",
    "\n",
    "Pour diminuer la taille de nos images latentes (celles entre les couches de l'encodeur) : on applique un pas de 2 pour nos convolutions.\n",
    "\n",
    "Pour augmenter la taille des images latentes (celles entre les couches du décodeur) : des convolutions transposées à pas de 2.\n",
    "\n",
    "![](https://miro.medium.com/v2/resize:fit:720/1*kOThnLR8Fge_AJcHrkR3dg.gif)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class StrideConvBlock(nn.Sequential):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        norm_groups: int,\n",
    "        mode: Literal[\"up\", \"down\"],\n",
    "    ) -> None:\n",
    "        conv_constructors = {\n",
    "            \"up\": nn.ConvTranspose2d,\n",
    "            \"down\": nn.Conv2d,\n",
    "        }\n",
    "\n",
    "        super().__init__(\n",
    "            conv_constructors[mode](\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size=(4, 4),\n",
    "                padding=(1, 1),\n",
    "                stride=(2, 2)\n",
    "            ),\n",
    "            nn.Mish(),\n",
    "            nn.GroupNorm(norm_groups, out_channels),\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "down_block = StrideConvBlock(8, 16, 4, \"down\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "out_2 = down_block(out)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "out.size(), out_2.size()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "up_block = StrideConvBlock(16, 8, 4, \"up\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "out_3 = up_block(out_2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "out_2.size(), out_3.size()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Time embedding\n",
    "\n",
    "Nous disposons maintenant des briques de base pour notre U-Net. Il ne manque plus qu'à intégrer le paramètre supplémentaire représentant l'indice de l'étape dans le processus de diffusion."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
